{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ecce3a-a7d5-4756-94dc-8b0c15c126d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
      "    Setting a new token will erase the existing one.\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Enter your token (input will not be visible): Traceback (most recent call last):\n",
      "  File \"/home/pengejeen/.local/bin/huggingface-cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/pengejeen/.local/lib/python3.10/site-packages/huggingface_hub/commands/huggingface_cli.py\", line 51, in main\n",
      "    service.run()\n",
      "  File \"/home/pengejeen/.local/lib/python3.10/site-packages/huggingface_hub/commands/user.py\", line 98, in run\n",
      "    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)\n",
      "  File \"/home/pengejeen/.local/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 115, in login\n",
      "    interpreter_login(new_session=new_session, write_permission=write_permission)\n",
      "  File \"/home/pengejeen/.local/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 191, in interpreter_login\n",
      "    token = getpass(\"Enter your token (input will not be visible): \")\n",
      "  File \"/usr/lib/python3.10/getpass.py\", line 77, in unix_getpass\n",
      "    passwd = _raw_input(prompt, stream, input=input)\n",
      "  File \"/usr/lib/python3.10/getpass.py\", line 146, in _raw_input\n",
      "    line = input.readline()\n",
      "  File \"/usr/lib/python3.10/codecs.py\", line 319, in decode\n",
      "    def decode(self, input, final=False):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d063658f-0326-4bdd-82d7-5035bfe112fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7f50beaec2450da79fcbeb8968d635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da674a6f027d477ab9e0829c8e479ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 done\n",
      "2 done\n",
      "3 done\n",
      "4 done\n",
      "5 done\n",
      "6 done\n",
      "7 done\n",
      "8 done\n",
      "9 done\n",
      "10 done\n",
      "11 done\n",
      "12 done\n",
      "13 done\n",
      "14 done\n",
      "15 done\n",
      "16 done\n",
      "17 done\n",
      "18 done\n",
      "19 done\n",
      "20 done\n",
      "21 done\n",
      "22 done\n",
      "23 done\n",
      "24 done\n",
      "25 done\n",
      "26 done\n",
      "27 done\n",
      "28 done\n",
      "29 done\n",
      "30 done\n",
      "31 done\n",
      "32 done\n",
      "33 done\n",
      "34 done\n",
      "35 done\n",
      "36 done\n",
      "37 done\n",
      "38 done\n",
      "39 done\n",
      "40 done\n",
      "41 done\n",
      "42 done\n",
      "43 done\n",
      "44 done\n",
      "45 done\n",
      "46 done\n",
      "47 done\n",
      "48 done\n",
      "49 done\n",
      "50 done\n",
      "51 done\n",
      "52 done\n",
      "53 done\n",
      "54 done\n",
      "55 done\n",
      "56 done\n",
      "57 done\n",
      "58 done\n",
      "59 done\n",
      "60 done\n",
      "61 done\n",
      "62 done\n",
      "63 done\n",
      "64 done\n",
      "65 done\n",
      "66 done\n",
      "67 done\n",
      "68 done\n",
      "69 done\n",
      "70 done\n",
      "71 done\n",
      "72 done\n",
      "73 done\n",
      "74 done\n",
      "75 done\n",
      "76 done\n",
      "77 done\n",
      "78 done\n",
      "79 done\n",
      "80 done\n",
      "81 done\n",
      "82 done\n",
      "83 done\n",
      "84 done\n",
      "85 done\n",
      "86 done\n",
      "87 done\n",
      "88 done\n",
      "89 done\n",
      "90 done\n",
      "91 done\n",
      "92 done\n",
      "93 done\n",
      "94 done\n",
      "95 done\n",
      "96 done\n",
      "97 done\n",
      "98 done\n",
      "99 done\n",
      "100 done\n",
      "101 done\n",
      "102 done\n",
      "103 done\n",
      "104 done\n",
      "105 done\n",
      "106 done\n",
      "107 done\n",
      "108 done\n",
      "109 done\n",
      "110 done\n",
      "111 done\n",
      "112 done\n",
      "113 done\n",
      "114 done\n",
      "115 done\n",
      "116 done\n",
      "117 done\n",
      "118 done\n",
      "119 done\n",
      "120 done\n",
      "121 done\n",
      "122 done\n",
      "123 done\n",
      "124 done\n",
      "125 done\n",
      "126 done\n",
      "127 done\n",
      "128 done\n",
      "129 done\n",
      "130 done\n",
      "131 done\n",
      "132 done\n",
      "133 done\n",
      "134 done\n",
      "135 done\n",
      "136 done\n",
      "137 done\n",
      "138 done\n",
      "139 done\n",
      "140 done\n",
      "141 done\n",
      "142 done\n",
      "143 done\n",
      "144 done\n",
      "145 done\n",
      "146 done\n",
      "147 done\n",
      "148 done\n",
      "149 done\n",
      "150 done\n",
      "151 done\n",
      "152 done\n",
      "153 done\n",
      "154 done\n",
      "155 done\n",
      "156 done\n",
      "157 done\n",
      "158 done\n",
      "159 done\n",
      "160 done\n",
      "161 done\n",
      "162 done\n",
      "163 done\n",
      "164 done\n",
      "165 done\n",
      "166 done\n",
      "167 done\n",
      "168 done\n",
      "169 done\n",
      "170 done\n",
      "171 done\n",
      "172 done\n",
      "173 done\n",
      "174 done\n",
      "175 done\n",
      "176 done\n",
      "177 done\n",
      "178 done\n",
      "179 done\n",
      "180 done\n",
      "181 done\n",
      "182 done\n",
      "183 done\n",
      "184 done\n",
      "185 done\n",
      "186 done\n",
      "187 done\n",
      "188 done\n",
      "189 done\n",
      "190 done\n",
      "191 done\n",
      "192 done\n",
      "193 done\n",
      "194 done\n",
      "195 done\n",
      "196 done\n",
      "197 done\n",
      "198 done\n",
      "199 done\n",
      "200 done\n",
      "201 done\n",
      "202 done\n",
      "203 done\n",
      "204 done\n",
      "205 done\n",
      "206 done\n",
      "207 done\n",
      "208 done\n",
      "209 done\n",
      "210 done\n",
      "211 done\n",
      "212 done\n",
      "213 done\n",
      "214 done\n",
      "215 done\n",
      "216 done\n",
      "217 done\n",
      "218 done\n",
      "219 done\n",
      "220 done\n",
      "221 done\n",
      "222 done\n",
      "223 done\n",
      "224 done\n",
      "225 done\n",
      "226 done\n",
      "227 done\n",
      "228 done\n",
      "229 done\n",
      "230 done\n",
      "231 done\n",
      "232 done\n",
      "233 done\n",
      "234 done\n",
      "235 done\n",
      "236 done\n",
      "237 done\n",
      "238 done\n",
      "239 done\n",
      "240 done\n",
      "241 done\n",
      "242 done\n",
      "243 done\n",
      "244 done\n",
      "245 done\n",
      "246 done\n",
      "247 done\n",
      "248 done\n",
      "249 done\n",
      "250 done\n",
      "251 done\n",
      "252 done\n",
      "253 done\n",
      "254 done\n",
      "255 done\n",
      "256 done\n",
      "257 done\n",
      "258 done\n",
      "259 done\n",
      "260 done\n",
      "261 done\n",
      "262 done\n",
      "263 done\n",
      "264 done\n",
      "265 done\n",
      "266 done\n",
      "267 done\n",
      "268 done\n",
      "269 done\n",
      "270 done\n",
      "271 done\n",
      "272 done\n",
      "273 done\n",
      "274 done\n",
      "275 done\n",
      "276 done\n",
      "277 done\n",
      "278 done\n",
      "279 done\n",
      "280 done\n",
      "281 done\n",
      "282 done\n",
      "283 done\n",
      "284 done\n",
      "285 done\n",
      "286 done\n",
      "287 done\n",
      "288 done\n",
      "289 done\n",
      "290 done\n",
      "291 done\n",
      "292 done\n",
      "293 done\n",
      "294 done\n",
      "295 done\n",
      "296 done\n",
      "297 done\n",
      "298 done\n",
      "299 done\n",
      "300 done\n",
      "301 done\n",
      "302 done\n",
      "303 done\n",
      "304 done\n",
      "305 done\n",
      "306 done\n",
      "307 done\n",
      "308 done\n",
      "309 done\n",
      "310 done\n",
      "311 done\n",
      "312 done\n",
      "313 done\n",
      "314 done\n",
      "315 done\n",
      "316 done\n",
      "317 done\n",
      "318 done\n",
      "319 done\n",
      "320 done\n",
      "321 done\n",
      "322 done\n",
      "323 done\n",
      "324 done\n",
      "325 done\n",
      "326 done\n",
      "327 done\n",
      "328 done\n",
      "329 done\n",
      "330 done\n",
      "331 done\n",
      "332 done\n",
      "333 done\n",
      "334 done\n",
      "335 done\n",
      "336 done\n",
      "337 done\n",
      "338 done\n",
      "339 done\n",
      "340 done\n",
      "341 done\n",
      "342 done\n",
      "343 done\n",
      "344 done\n",
      "345 done\n",
      "346 done\n",
      "347 done\n",
      "348 done\n",
      "349 done\n",
      "350 done\n",
      "351 done\n",
      "352 done\n",
      "353 done\n",
      "354 done\n",
      "355 done\n",
      "356 done\n",
      "357 done\n",
      "358 done\n",
      "359 done\n",
      "360 done\n",
      "361 done\n",
      "362 done\n",
      "363 done\n",
      "364 done\n",
      "365 done\n",
      "366 done\n",
      "367 done\n",
      "368 done\n",
      "369 done\n",
      "370 done\n",
      "371 done\n",
      "372 done\n",
      "373 done\n",
      "374 done\n",
      "375 done\n",
      "376 done\n",
      "377 done\n",
      "378 done\n",
      "379 done\n",
      "380 done\n",
      "381 done\n",
      "382 done\n",
      "383 done\n",
      "384 done\n",
      "385 done\n",
      "386 done\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "# 스트리밍 옵션으로 데이터셋 로드\n",
    "dataset = load_dataset('simon3000/genshin-voice', split='train', streaming=True)\n",
    "\n",
    "# 한국어 Paimon 음성과 전사(transcription)가 있는 데이터를 필터링하는 함수 정의\n",
    "def filter_korean_paimon(example):\n",
    "    return example['language'] == 'Korean' and example['speaker'] == 'Paimon' and example['transcription'] != ''\n",
    "\n",
    "# 폴더 생성\n",
    "paimon_folder = 'paimon_voices'\n",
    "os.makedirs(paimon_folder, exist_ok=True)\n",
    "# 데이터셋의 일부분만 처리\n",
    "batch_size = 100  # 한 번에 처리할 데이터 개수\n",
    "i = 1\n",
    "\n",
    "# 데이터 처리 루프\n",
    "start_index = 0  # 시작 인덱스 설정\n",
    "while True:\n",
    "    # 데이터셋에서 시작 인덱스부터 배치를 가져옴\n",
    "    batch = list(islice(dataset, start_index, start_index + batch_size))\n",
    "    if not batch:\n",
    "        break\n",
    "\n",
    "    for example in batch:\n",
    "        # 필터링 조건 확인\n",
    "        if filter_korean_paimon(example):\n",
    "            audio_path = os.path.join(paimon_folder, f'{i}_audio.wav')  # 오디오 파일 저장 경로\n",
    "            transcription_path = os.path.join(paimon_folder, f'{i}_transcription.txt')  # 전사 파일 저장 경로\n",
    "\n",
    "            # 오디오 데이터 저장\n",
    "            audio = example['audio']\n",
    "            sf.write(audio_path, audio['array'], audio['sampling_rate'])\n",
    "\n",
    "            # 전사 데이터 저장\n",
    "            with open(transcription_path, 'w') as transcription_file:\n",
    "                transcription_file.write(example['transcription'])\n",
    "\n",
    "            print(f'{i} done')\n",
    "            i += 1\n",
    "\n",
    "    # 다음 반복을 위해 시작 인덱스 업데이트\n",
    "    start_index += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39da49a8-901d-4cce-ada9-f0f19cac7e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import whisper\n",
    "\n",
    "PATH = \"/home/pengejeen/paymon_v0.0.1/paimon_llama2-enhanced/tts_paimon\"\n",
    "\n",
    "model = whisper.load_model(\"small\")\n",
    "i = 1\n",
    "\n",
    "result_txt = \"\"\n",
    "paimon_folder = 'datasets/wavs'\n",
    "\n",
    "while True:\n",
    "    tmp_txt = \"\"\n",
    "    try:\n",
    "        audio_path = f'{i}_audio'  # 오디오 파일 저장 경로\n",
    "        transcription = model.transcribe(f\"{PATH}/datasets/wavs/{audio_path}.wav\", language=\"ko\")[\"text\"]\n",
    "\n",
    "        tmp_txt = f\"{audio_path}|{transcription}|{transcription}\\n\"\n",
    "        result_txt += tmp_txt\n",
    "        i += 1\n",
    "    except:\n",
    "        print(\"done\")\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41386afa-5d4b-427b-bbf8-4da7bb6603a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1_audio| 응? 벌써 정답을 맞췄다고? 설마 네가 내 수습게끼 쉬었어?| 응? 벌써 정답을 맞췄다고? 설마 네가 내 수습게끼 쉬었어?\\n2_audio| 우와! 이게 휴식을 즐기는 개설인인가? 정말 달라 보여! 개설이는 언제 어디서든! 별과 시면을 향해! 라고 하는 줄 알았어!| 우와! 이게 휴식을 즐기는 개설인인가? 정말 달라 보여! 개설이는 언제 어디서든! 별과 시면을 향해! 라고 하는 줄 알았어!\\n3_audio| 아이, 전문가가 왔잖아| 아이, 전문가가 왔잖아\\n4_audio| 설마 소두 우리의 기운을 못 느끼는 건가?| 설마 소두 우리의 기운을 못 느끼는 건가?\\n5_audio| 동마령 손에서 유적 하나를 뺏어서 온 셈이니까| 동마령 손에서 유적 하나를 뺏어서 온 셈이니까\\n6_audio| 으아, 정말 스네즈 나야스러운 장인한 동요네| 으아, 정말 스네즈 나야스러운 장인한 동요네\\n7_audio| 휘휘! 오예!| 휘휘! 오예!\\n8_audio| 그럼, 주리아가 말한 아이에 대한 일들도 다 지어낸 거야?| 그럼, 주리아가 말한 아이에 대한 일들도 다 지어낸 거야?\\n9_audio| 소원 주문에 관한 건 물어볼 틈이 없네 사람 목숨이 달린 일이라니까 일부터 해결하고 보자| 소원 주문에 관한 건 물어볼 틈이 없네 사람 목숨이 달린 일이라니까 일부터 해결하고 보자\\n10_audio| 설마 방금 몰래 타르탤리아를 따라간 건가?| 설마 방금 몰래 타르탤리아를 따라간 건가?\\n11_audio| 하하! 어때? 죽지는 않겠지?| 하하! 어때? 죽지는 않겠지?\\n12_audio| 으이! 베이먼은 화났어! 어쩐지 쿨하게 가더라니!| 으이! 베이먼은 화났어! 어쩐지 쿨하게 가더라니!\\n13_audio| 맞아! 최주할 줄 아는 게 바로 강시야!| 맞아! 최주할 줄 아는 게 바로 강시야!\\n14_audio| 으야아 새 친구 앞에서 이렇게 망신줄거야?| 으야아 새 친구 앞에서 이렇게 망신줄거야?\\n15_audio| 사실 밥 먹을 때부터 궁금했던 건데| 사실 밥 먹을 때부터 궁금했던 건데\\n16_audio| 흠! 캐러벤을 약하란 나쁜 꽃게 녀석! 어딜 도망가려고?| 흠! 캐러벤을 약하란 나쁜 꽃게 녀석! 어딜 도망가려고?\\n17_audio| 응, 이해해. 언젠가 나랑 여행자가 헤어지는 날에 오면 나도 적응이 안 될 거야. 허공에 혼자 말을 할지도 모르지.| 응, 이해해. 언젠가 나랑 여행자가 헤어지는 날에 오면 나도 적응이 안 될 거야. 허공에 혼자 말을 할지도 모르지.\\n18_audio| 다행히 아래로 떨어지지는 않았네 정말 다행이야| 다행히 아래로 떨어지지는 않았네 정말 다행이야\\n19_audio| 와! 창문이 제대로 안 다쳤나봐! 내가 들어가 볼게!| 와! 창문이 제대로 안 다쳤나봐! 내가 들어가 볼게!\\n20_audio| 뜸들이지 말고 이제 무슨 일인지 말해 볼래?| 뜸들이지 말고 이제 무슨 일인지 말해 볼래?\\n21_audio| 우와 엄청 큰 물방울이야| 우와 엄청 큰 물방울이야\\n22_audio| 근데 사실은 아카데미아의 방법을 인정하지 않는 거지? 사막에 대한 미안한 마음도 있고… 에휴… 이건 그냥 문제를 회피하고 있는 거잖아!| 근데 사실은 아카데미아의 방법을 인정하지 않는 거지? 사막에 대한 미안한 마음도 있고… 에휴… 이건 그냥 문제를 회피하고 있는 거잖아!\\n23_audio| 인형이라고? 그걸 어떻게 한 거야?| 인형이라고? 그걸 어떻게 한 거야?\\n24_audio| 엄청 멀리서 왔네? 우리 가게가 벌써 그렇게 유명해진 거야?| 엄청 멀리서 왔네? 우리 가게가 벌써 그렇게 유명해진 거야?\\n25_audio| 아! 무슨 말인지 알겠어!| 아! 무슨 말인지 알겠어!\\n26_audio| 나비아가 사주는 밥이니까 난 무조건 좋아! 고민할 필요도 없지!| 나비아가 사주는 밥이니까 난 무조건 좋아! 고민할 필요도 없지!\\n27_audio| 오빠가 너무 보고 싶어서 순간적으로 생긴 환상인가?| 오빠가 너무 보고 싶어서 순간적으로 생긴 환상인가?\\n28_audio| 말세!| 말세!\\n29_audio| 우리도 도와줄게! 신호부의 노력을 봐서라도 이번 행사가 산으로 가게 될 순 없지!| 우리도 도와줄게! 신호부의 노력을 봐서라도 이번 행사가 산으로 가게 될 순 없지!\\n30_audio| 좀 하는데? 역시 여행자야!| 좀 하는데? 역시 여행자야!\\n31_audio| 야단! 니가 증거를 숨긴 건 아니겠지?| 야단! 니가 증거를 숨긴 건 아니겠지?\\n32_audio| 니 오빠가 너보다 먼저 깨어난 것 같은데? 얼마나 일찍겠는지 모르는 거지?| 니 오빠가 너보다 먼저 깨어난 것 같은데? 얼마나 일찍겠는지 모르는 거지?\\n33_audio| 그게 기분이 좋은 거였구나| 그게 기분이 좋은 거였구나\\n34_audio| 맞아 맞아! 어제 그거 굉장했지? 아직도 그 맛이 느껴질 정도야!| 맞아 맞아! 어제 그거 굉장했지? 아직도 그 맛이 느껴질 정도야!\\n35_audio| 폭풍 장벽이다!| 폭풍 장벽이다!\\n36_audio| 이봐, 얘 좀 이상해| 이봐, 얘 좀 이상해\\n37_audio| 응 맞아! 뭔가 서프라이즈가 있을 수도 있잖아?| 응 맞아! 뭔가 서프라이즈가 있을 수도 있잖아?\\n38_audio| 아! 알겠다! 병 안에 물을 담은 다음, 병을 뒤집으면 물이 사라지는 맛을 있잖아!| 아! 알겠다! 병 안에 물을 담은 다음, 병을 뒤집으면 물이 사라지는 맛을 있잖아!\\n39_audio| 으아! 우리 또 나름의 사정이 있다고!| 으아! 우리 또 나름의 사정이 있다고!\\n40_audio| 난 날아다니잖아. 걸어다닌 적은 한 번도 없는걸?| 난 날아다니잖아. 걸어다닌 적은 한 번도 없는걸?\\n41_audio| 그럼 다른 사람들한테 가보자! 누가 좋을까? 다이나리는 기권했고 사이노는 방금 봤으니까| 그럼 다른 사람들한테 가보자! 누가 좋을까? 다이나리는 기권했고 사이노는 방금 봤으니까\\n42_audio| 아휴, 자신에게 너무 엄격하잖아 그게 바로 공감이야| 아휴, 자신에게 너무 엄격하잖아 그게 바로 공감이야\\n43_audio| 아이 이봐! 뭘 그렇게 부끄러워하는 거야! 치! 내가 하는 걸 잘 보라고!| 아이 이봐! 뭘 그렇게 부끄러워하는 거야! 치! 내가 하는 걸 잘 보라고!\\n44_audio| 어이... 하지만 그렇게 되면 불구는이가 푸른 언니의 영원을 배신한 게 되잖아!| 어이... 하지만 그렇게 되면 불구는이가 푸른 언니의 영원을 배신한 게 되잖아!\\n45_audio| 근데 네가 이렇게까지 할 줄은 몰랐어| 근데 네가 이렇게까지 할 줄은 몰랐어\\n46_audio| 뭐?| 뭐?\\n47_audio| 하... 이 정도면 됐을 거야! 다치진 않았지?| 하... 이 정도면 됐을 거야! 다치진 않았지?\\n48_audio| 근데 여행자가 잘할 수 있을까? 요리의 맛도 고려해야 하잖아| 근데 여행자가 잘할 수 있을까? 요리의 맛도 고려해야 하잖아\\n49_audio| 그만큼 좋아했다는 거지| 그만큼 좋아했다는 거지\\n50_audio| 마신의 힘이 남아있어야 만 연구 가치가 있는 거야?| 마신의 힘이 남아있어야 만 연구 가치가 있는 거야?\\n51_audio| 다만 메로피드 요새 이런 일을 하는 사람이 있다는 건 좀 의외 왔어| 다만 메로피드 요새 이런 일을 하는 사람이 있다는 건 좀 의외 왔어\\n52_audio| 그럼 직접 아내를 찾아가 이야기를 나누면 되는 거잖아 굳이 꿈에서 이야기를 나눌 필요가 있을까?| 그럼 직접 아내를 찾아가 이야기를 나누면 되는 거잖아 굳이 꿈에서 이야기를 나눌 필요가 있을까?\\n53_audio| 음..어디부터 시작할까?| 음..어디부터 시작할까?\\n54_audio| 왜? 사유 너도 담육션을 참가로 온 거야?| 왜? 사유 너도 담육션을 참가로 온 거야?\\n55_audio| 그런가?| 그런가?\\n56_audio| 선인은 원래 그렇잖아! 우리가 본 선인들도 모두 속세를 멀리하고 독립적이었어! 인간들과는 전혀 다른 느낌이었지!| 선인은 원래 그렇잖아! 우리가 본 선인들도 모두 속세를 멀리하고 독립적이었어! 인간들과는 전혀 다른 느낌이었지!\\n57_audio| 뭐가 뭔지 모르겠어| 뭐가 뭔지 모르겠어\\n58_audio| 안녕!| 안녕!\\n59_audio| 비니언은 결국 못 찾았지만| 비니언은 결국 못 찾았지만\\n60_audio| 아이, 지금 자기 자랑한 거지| 아이, 지금 자기 자랑한 거지\\n61_audio| 아휴, 앞쪽엔 길이 없어 에이, 진짜 대체 부채를 어디다 숨긴 거야?| 아휴, 앞쪽엔 길이 없어 에이, 진짜 대체 부채를 어디다 숨긴 거야?\\n62_audio| 뭐? 라이트 누벌에 나온 방법이라고?| 뭐? 라이트 누벌에 나온 방법이라고?\\n63_audio| 리얼 사람들이 좀 딱하네| 리얼 사람들이 좀 딱하네\\n64_audio| 정말? 우리가 그렇게 보고 싶었어?| 정말? 우리가 그렇게 보고 싶었어?\\n65_audio| 진짜 당당하게 앉아 버리네 책까지 꺼냈어| 진짜 당당하게 앉아 버리네 책까지 꺼냈어\\n66_audio| 응 응! 모험에서의 경험을 활용할 수 있겠어!| 응 응! 모험에서의 경험을 활용할 수 있겠어!\\n67_audio| 아! 그럼 치사토가 편지 이야기를 알아들었겠지?| 아! 그럼 치사토가 편지 이야기를 알아들었겠지?\\n68_audio| 아... 비슷한 말을 어디선가 들은 것 같아 아 맞다! 퇴설이는 여기에 무슨 일로 온 거야?| 아... 비슷한 말을 어디선가 들은 것 같아 아 맞다! 퇴설이는 여기에 무슨 일로 온 거야?\\n69_audio| ion| ion\\n70_audio| 우와 정말? 다행이다! 우리가 꽤 괜찮은 물건을 골랐나봐| 우와 정말? 다행이다! 우리가 꽤 괜찮은 물건을 골랐나봐\\n71_audio| 누구인지는 모르겠지만... 면복을...| 누구인지는 모르겠지만... 면복을...\\n72_audio| 나이다. 원래 화신탄신 축제는 네 꿈처럼 보냈어야 했어. 사람들이 즐겁게 네 생일을 축하하면서 말이야.| 나이다. 원래 화신탄신 축제는 네 꿈처럼 보냈어야 했어. 사람들이 즐겁게 네 생일을 축하하면서 말이야.\\n73_audio| 응! 우리도 출발하자!| 응! 우리도 출발하자!\\n74_audio| 피카안 느낌으로 만들면 되지!| 피카안 느낌으로 만들면 되지!\\n75_audio| 어, 처음 본 건 아닌가?| 어, 처음 본 건 아닌가?\\n76_audio| 발자국은 여기까지 이어져! 어? 저쪽에 유적 가디언이 하나 있어!| 발자국은 여기까지 이어져! 어? 저쪽에 유적 가디언이 하나 있어!\\n77_audio| 야! 이제 어떡해!| 야! 이제 어떡해!\\n78_audio| 이제 어떡할 거야? 가자! 어떻게 할지 생각해도었지?| 이제 어떡할 거야? 가자! 어떻게 할지 생각해도었지?\\n79_audio| 하지만 넌 꼭 해야 할 일이 두 가지 있다고 했는데 아직 하나 더 남았잖아| 하지만 넌 꼭 해야 할 일이 두 가지 있다고 했는데 아직 하나 더 남았잖아\\n80_audio| 새하얀 합손인이라 우린 하늘색이랑 흑갈색 밖에 모르는데| 새하얀 합손인이라 우린 하늘색이랑 흑갈색 밖에 모르는데\\n81_audio| 그래! 그럼 얼른 갔다 올게!| 그래! 그럼 얼른 갔다 올게!\\n82_audio| 음 나 알 것 같아| 음 나 알 것 같아\\n83_audio| 그래, 종면은 항상 거래는 공평해야 한다고 했잖아. 이 세상 어떤 물건이 신의 심장과 맞받고만한 가치가 있다는 거야?| 그래, 종면은 항상 거래는 공평해야 한다고 했잖아. 이 세상 어떤 물건이 신의 심장과 맞받고만한 가치가 있다는 거야?\\n84_audio| 그게 사실이라면 네 번째 석판에 그려진 일도 곧 일어나지 않을까?| 그게 사실이라면 네 번째 석판에 그려진 일도 곧 일어나지 않을까?\\n85_audio| 그리고 또 있어! 너랑 백출은 어떻게 한눈에 가양의 몸에 마신의 잔재가 남아있는 걸 발견한 거야?| 그리고 또 있어! 너랑 백출은 어떻게 한눈에 가양의 몸에 마신의 잔재가 남아있는 걸 발견한 거야?\\n86_audio| 어째 든 나이다를 위해서라도 다음 목적지로 이동해야 하지 않을까?| 어째 든 나이다를 위해서라도 다음 목적지로 이동해야 하지 않을까?\\n87_audio| 아니 그냥 한번 구경해 보고 싶을 뿐이야| 아니 그냥 한번 구경해 보고 싶을 뿐이야\\n88_audio| 여기도 아무것도 없어! 호코르만 것 같아!| 여기도 아무것도 없어! 호코르만 것 같아!\\n89_audio| 우왕!| 우왕!\\n90_audio| 어디 가는데?| 어디 가는데?\\n91_audio| 여행자의 촬영 실력이 네 마음에 들면 안심하고 우리 팀에 합류하는 거야! 어때?| 여행자의 촬영 실력이 네 마음에 들면 안심하고 우리 팀에 합류하는 거야! 어때?\\n92_audio| 응? 뭐라 적혀있는데?| 응? 뭐라 적혀있는데?\\n93_audio| 그..그..그치만.. 만약에 만약에 만약에라도 진짜 악기 같은 거면.. 어떻게..| 그..그..그치만.. 만약에 만약에 만약에라도 진짜 악기 같은 거면.. 어떻게..\\n94_audio| 또 가버렸어!| 또 가버렸어!\\n95_audio| 하이팟이야! 안심해! 테이나리가 음식을 가져다달라고 우리 보냈어 여기 같이 보는 편지야!| 하이팟이야! 안심해! 테이나리가 음식을 가져다달라고 우리 보냈어 여기 같이 보는 편지야!\\n96_audio| 사막 출신이었구나. 정말 특이한 경우 내 스물의 성에서 보이는 사막주민의 대부분은 용병이던데.| 사막 출신이었구나. 정말 특이한 경우 내 스물의 성에서 보이는 사막주민의 대부분은 용병이던데.\\n97_audio| 흔치 않은 기회야! 히히! 이참에 때 삶의 철학을 느껴보라구!| 흔치 않은 기회야! 히히! 이참에 때 삶의 철학을 느껴보라구!\\n98_audio| 엄청 큰 참세다!| 엄청 큰 참세다!\\n99_audio| 고고! 오랜만이네!| 고고! 오랜만이네!\\n100_audio| 네가 골라! 이미 들어본 거면 넘어가라고 할게!| 네가 골라! 이미 들어본 거면 넘어가라고 할게!\\n101_audio| 신난다! 축하파티 열자!| 신난다! 축하파티 열자!\\n102_audio| 도와줄까? 돌아오긴 했는데 딱히 할 것도 없고 우리 데리고 다니다가 이리 끝나면 같이 히히히| 도와줄까? 돌아오긴 했는데 딱히 할 것도 없고 우리 데리고 다니다가 이리 끝나면 같이 히히히\\n103_audio| 말 하나 전하고 오는 게 이렇게 오래 걸린다고?| 말 하나 전하고 오는 게 이렇게 오래 걸린다고?\\n104_audio| 땅에 있는 문의가 엉망이 됐어 주변에 이 문의를 복구시킬 만한 방법이 있는지 찾아볼까?| 땅에 있는 문의가 엉망이 됐어 주변에 이 문의를 복구시킬 만한 방법이 있는지 찾아볼까?\\n105_audio| 공연장에서 눈에 띄는 것들은 전부 확인한 것 같아 미니 쪽은 경비대랑 얘기가 끝났으려나| 공연장에서 눈에 띄는 것들은 전부 확인한 것 같아 미니 쪽은 경비대랑 얘기가 끝났으려나\\n106_audio| 음.. 일단 저거 두고 나중에 같이 생각해보자| 음.. 일단 저거 두고 나중에 같이 생각해보자\\n107_audio| 왜... 왜 제자리로 돌아왔지?| 왜... 왜 제자리로 돌아왔지?\\n108_audio| 걸릴 걸 연배 두고 추천한 거야?| 걸릴 걸 연배 두고 추천한 거야?\\n109_audio| 루비에 트는 평소에 어떤 음료를 마시려나? 하! 고급 포도주 같은 거일까?| 루비에 트는 평소에 어떤 음료를 마시려나? 하! 고급 포도주 같은 거일까?\\n110_audio| 잠깐! 우리라고! 왜 또 그런 적대적인 표정이야!| 잠깐! 우리라고! 왜 또 그런 적대적인 표정이야!\\n111_audio| 오! 그렇다면!| 오! 그렇다면!\\n112_audio| 갑자기 진지하게 군다고 용서해줄 것 같아| 갑자기 진지하게 군다고 용서해줄 것 같아\\n113_audio| 오라... 정말 우연히 아닌 거야? 설마 세탈가 겸비병뿐만 아니라 성하는 사람들도 일찍 잠들게 해서 우리를 위해 길을 터주기라도 한 건가?| 오라... 정말 우연히 아닌 거야? 설마 세탈가 겸비병뿐만 아니라 성하는 사람들도 일찍 잠들게 해서 우리를 위해 길을 터주기라도 한 건가?\\n114_audio| 저 사람들을 따돌리고 얼른 두뇌을 자들을 쫓아가자!| 저 사람들을 따돌리고 얼른 두뇌을 자들을 쫓아가자!\\n115_audio| 와 정말 조심성이 강하네 풍기간이라서 그런건가?| 와 정말 조심성이 강하네 풍기간이라서 그런건가?\\n116_audio| 그럼 계획을 짜야 하는 거 아니야? 시는 전혀 상관없잖아!| 그럼 계획을 짜야 하는 거 아니야? 시는 전혀 상관없잖아!\\n117_audio| 쭉쭉!| 쭉쭉!\\n118_audio| 그럼 역시 빌망을 찾으러 갈 수밖에 없겠네| 그럼 역시 빌망을 찾으러 갈 수밖에 없겠네\\n119_audio| 아휴, 미안| 아휴, 미안\\n120_audio| 그럴 줄 알았어! 버선문이 또다시 폭주할 거란 한이아의 추측에 난 동의할 수 없어! 둥둥 모자처럼 인간과 사이좋게 지낼 수 있는 착한 버선문도 있다고!| 그럴 줄 알았어! 버선문이 또다시 폭주할 거란 한이아의 추측에 난 동의할 수 없어! 둥둥 모자처럼 인간과 사이좋게 지낼 수 있는 착한 버선문도 있다고!\\n121_audio| 언제까지 기다려야 효과가 나타날까?| 언제까지 기다려야 효과가 나타날까?\\n122_audio| 맞다! 그거 기억해! 호두가 요즘 교역마을에 가고 싶어 했다고 종료가 그랬잖아!| 맞다! 그거 기억해! 호두가 요즘 교역마을에 가고 싶어 했다고 종료가 그랬잖아!\\n123_audio| 음... 그럼 우선 요임이아를 찾으러 하나밀짝하에 가보자!| 음... 그럼 우선 요임이아를 찾으러 하나밀짝하에 가보자!\\n124_audio| 하아... 피곤하다... 내일도 얌전히 일어나서 일해야겠네 특별 호가 쿠폰이 없으면 특권도 누릴 수 없으니까| 하아... 피곤하다... 내일도 얌전히 일어나서 일해야겠네 특별 호가 쿠폰이 없으면 특권도 누릴 수 없으니까\\n125_audio| 히히! 니가 지어준 이름도 괜찮지만, 셔베트라는 이름을 더 좋아하는 것 같아!| 히히! 니가 지어준 이름도 괜찮지만, 셔베트라는 이름을 더 좋아하는 것 같아!\\n126_audio| 너 기억력 진짜 좋구나!| 너 기억력 진짜 좋구나!\\n127_audio| 사실 쭉 궁금했어! 뉴비에트 넌 물의 용황이면서 왜 인간서회 최고신판관이 된 거야?| 사실 쭉 궁금했어! 뉴비에트 넌 물의 용황이면서 왜 인간서회 최고신판관이 된 거야?\\n128_audio| 아무래도 니 오빠는 시명교단을 이끌고 있고 시면사도 보다 지위도 더 높은 것 같아! 최고 통솔자인지는 아직 잘 모르겠지만| 아무래도 니 오빠는 시명교단을 이끌고 있고 시면사도 보다 지위도 더 높은 것 같아! 최고 통솔자인지는 아직 잘 모르겠지만\\n129_audio| 물론 나도 다음에 만날 땐 네가 귀신풍댕이가 조종하는 초대형 기계풍댕이를 만들어냈으면 좋겠어!| 물론 나도 다음에 만날 땐 네가 귀신풍댕이가 조종하는 초대형 기계풍댕이를 만들어냈으면 좋겠어!\\n130_audio| 이봐! 너무 막연한 추리 아니야?| 이봐! 너무 막연한 추리 아니야?\\n131_audio| 으휴 안주거리가 된 것 같아 별로인데| 으휴 안주거리가 된 것 같아 별로인데\\n132_audio| 아! 그러니까 우리한테 옷을 입혀본다는 얘기지?| 아! 그러니까 우리한테 옷을 입혀본다는 얘기지?\\n133_audio| 요소기 흐린 것 같은데 한번 봐보자| 요소기 흐린 것 같은데 한번 봐보자\\n134_audio| 그나저나 어떻게 상품을 확인할 생각을 한 거야?| 그나저나 어떻게 상품을 확인할 생각을 한 거야?\\n135_audio| 뭐야? 그 시큰둥한 반응은? 이럴 땐 기분 좋아야 되는 거 아니야?| 뭐야? 그 시큰둥한 반응은? 이럴 땐 기분 좋아야 되는 거 아니야?\\n136_audio| 많이 괴로워 보여! 어떡해!| 많이 괴로워 보여! 어떡해!\\n137_audio| 무슨 말을 하는 건지는 모르겠지만 결론이 난 거지| 무슨 말을 하는 건지는 모르겠지만 결론이 난 거지\\n138_audio| 아... 저기... 범인은 바로 이번 사건의 희생자인 코엘이야!| 아... 저기... 범인은 바로 이번 사건의 희생자인 코엘이야!\\n139_audio| 눈빛을 보니까 정말 억울한 모양인데?| 눈빛을 보니까 정말 억울한 모양인데?\\n140_audio| 에이, 첫 번째 증거는 아무 소용이 없네 저 사람 처음부터 대처 방법을 생각해놨던 것 같은데 그럼 뭘 보여줄까?| 에이, 첫 번째 증거는 아무 소용이 없네 저 사람 처음부터 대처 방법을 생각해놨던 것 같은데 그럼 뭘 보여줄까?\\n141_audio| 으아! 뭐 뭐라고? 네가 돌이야? 엄청 무섭게 생긴 대장일 줄 알았는데...| 으아! 뭐 뭐라고? 네가 돌이야? 엄청 무섭게 생긴 대장일 줄 알았는데...\\n142_audio| 쉿! 고성당에 들어가니까 바람신 뒷담하는 그만해!| 쉿! 고성당에 들어가니까 바람신 뒷담하는 그만해!\\n143_audio| 그러니까 상금으로 집을 사고 싶다는 거잖아! 그치?| 그러니까 상금으로 집을 사고 싶다는 거잖아! 그치?\\n144_audio| 위토가 다시 돌아왔어!| 위토가 다시 돌아왔어!\\n145_audio| 휴... 겨우 그 악진하는 곳을 벗어났네...| 휴... 겨우 그 악진하는 곳을 벗어났네...\\n146_audio| 서비스는 우리도 할 수 있다고!| 서비스는 우리도 할 수 있다고!\\n147_audio| 호랑이도 제말하면 온다더니| 호랑이도 제말하면 온다더니\\n148_audio| 왜 그래, 미니? 들어본 이름이야?| 왜 그래, 미니? 들어본 이름이야?\\n149_audio| 아! 미코가 있었지!| 아! 미코가 있었지!\\n150_audio| 그거 나 아니거든? 그게 어떻게 나냐고!| 그거 나 아니거든? 그게 어떻게 나냐고!\\n151_audio| 몸은 괜찮아? 힘들면 무리하지 마!| 몸은 괜찮아? 힘들면 무리하지 마!\\n152_audio| 너랑 오랫동안 여행하면서 페이모는 이미 충분히 많은 걸 봤는데?| 너랑 오랫동안 여행하면서 페이모는 이미 충분히 많은 걸 봤는데?\\n153_audio|蛋|蛋\\n154_audio| 자막被 자막을 건물고 임자| 자막被 자막을 건물고 임자\\n155_audio| 우에! 덕분에 밥 맛이 떨어져 버렸잖아! 저리 치워!| 우에! 덕분에 밥 맛이 떨어져 버렸잖아! 저리 치워!\\n156_audio| 음... 칼라스가 조직 내부에 전파한 정보가 무엇인지는 알아내지 못했다!| 음... 칼라스가 조직 내부에 전파한 정보가 무엇인지는 알아내지 못했다!\\n157_audio| 그럼 뭔가 잘못된 거네!| 그럼 뭔가 잘못된 거네!\\n158_audio| 걱정 마! 가볼 만한 장소를 세 군데나 알아 냈으니까 한 곳씩 돌아보면 될 거야!| 걱정 마! 가볼 만한 장소를 세 군데나 알아 냈으니까 한 곳씩 돌아보면 될 거야!\\n159_audio| 전부 별명이야? 아니면 본인이 지은 이름인가? 특이하네| 전부 별명이야? 아니면 본인이 지은 이름인가? 특이하네\\n160_audio| 잠깐! 누가 바보라는 거야? 혹시라도 얘한테 위험한 일이 생길까 봐 따라온 거거든?| 잠깐! 누가 바보라는 거야? 혹시라도 얘한테 위험한 일이 생길까 봐 따라온 거거든?\\n161_audio| 환각이다| 환각이다\\n162_audio| 비경은 엄청 위험하니까 출발하기 전에 물자랑 도구들을 검사하는 것도 잊지 말고| 비경은 엄청 위험하니까 출발하기 전에 물자랑 도구들을 검사하는 것도 잊지 말고\\n163_audio| 고르라고? 다 똑같은 거 아니야?| 고르라고? 다 똑같은 거 아니야?\\n164_audio| 으아! 으이! 됐어! 아무것도 안 떠올라!| 으아! 으이! 됐어! 아무것도 안 떠올라!\\n165_audio|��나 grund에 삐져있죠?!|��나 grund에 삐져있죠?!\\n166_audio| 생전수치| 생전수치\\n167_audio| 나도 그렇게 생각해! 사이노! 혹시 그 미쳐버린 학자들이 아로마을에서 호금 단말기를 꼈는지 안 꼈는지 알아?| 나도 그렇게 생각해! 사이노! 혹시 그 미쳐버린 학자들이 아로마을에서 호금 단말기를 꼈는지 안 꼈는지 알아?\\n168_audio| 눈치챘어!| 눈치챘어!\\n169_audio| 그게 다 너네 짓이었어?| 그게 다 너네 짓이었어?\\n170_audio| 아... 수상한 게 딱 봐도 나쁜 사람 같거든?| 아... 수상한 게 딱 봐도 나쁜 사람 같거든?\\n171_audio| 어이, 가서 말이라도 걸어보는 게 좋지 않을까?| 어이, 가서 말이라도 걸어보는 게 좋지 않을까?\\n172_audio| 어서 저 못된 거트를 차차하자고!| 어서 저 못된 거트를 차차하자고!\\n173_audio| 그런데 미니가 안 보이네! 어디 갔지?| 그런데 미니가 안 보이네! 어디 갔지?\\n174_audio| 잠깐만... 생각해보니까 수매를 장미할 뜻은 일반 상품이었던 것 같아!| 잠깐만... 생각해보니까 수매를 장미할 뜻은 일반 상품이었던 것 같아!\\n175_audio| 옷 제작에 관해서는 릴루가 잘할 거야!| 옷 제작에 관해서는 릴루가 잘할 거야!\\n176_audio| 얘 몸에 영원히 빙이 돼도 정말 괜찮은 거야?| 얘 몸에 영원히 빙이 돼도 정말 괜찮은 거야?\\n177_audio| 참 우리가 테스트하는 동안 넌 뭐 할 거야?| 참 우리가 테스트하는 동안 넌 뭐 할 거야?\\n178_audio| 휴! 드디어 도착했다!| 휴! 드디어 도착했다!\\n179_audio| 이게 태지맛이 일기장인 것 같다| 이게 태지맛이 일기장인 것 같다\\n180_audio| 누가! 누가 좀 도와줘! 얘.. 얘가 어디 아픈가 봐!| 누가! 누가 좀 도와줘! 얘.. 얘가 어디 아픈가 봐!\\n181_audio| 응! 가끔은 쉽게 쉽게 가는 것도 좋지| 응! 가끔은 쉽게 쉽게 가는 것도 좋지\\n182_audio| 우와 정말 낭만적이네| 우와 정말 낭만적이네\\n183_audio| 니네 또 의무실로 갔다고?| 니네 또 의무실로 갔다고?\\n184_audio| 마무른 우리가 상대할게!| 마무른 우리가 상대할게!\\n185_audio| 카드 뒷면이랑 플레이어의 실력이 무슨 상관인데?| 카드 뒷면이랑 플레이어의 실력이 무슨 상관인데?\\n186_audio| 근데 너 라흐 만을 너무 세게 때린 것 같아| 근데 너 라흐 만을 너무 세게 때린 것 같아\\n187_audio| 근데 범위가 너무 좁은 건 아닐까? 마르시아기 범위를 좁힐 땐 사람이 무리 되는 걸 몰랐잖아!| 근데 범위가 너무 좁은 건 아닐까? 마르시아기 범위를 좁힐 땐 사람이 무리 되는 걸 몰랐잖아!\\n188_audio| 도면... 아! 할머니가 주전자 주실 때 도면도 같이 주셨잖아! 빨리 봐보자!| 도면... 아! 할머니가 주전자 주실 때 도면도 같이 주셨잖아! 빨리 봐보자!\\n189_audio| 안녕! 묻고 싶은 게 있는데!| 안녕! 묻고 싶은 게 있는데!\\n190_audio| 어... 계산이 틀렸다는 소리가 아니라...| 어... 계산이 틀렸다는 소리가 아니라...\\n191_audio| 응! 나중에 봐!| 응! 나중에 봐!\\n192_audio| 이 목소리는 이토잖아! 네가 왜 여기 있어?| 이 목소리는 이토잖아! 네가 왜 여기 있어?\\n193_audio| 내 환각인가? 저 추추족들 뭔가 좀 이상해 보이지 않아?| 내 환각인가? 저 추추족들 뭔가 좀 이상해 보이지 않아?\\n194_audio| 으!| 으!\\n195_audio|起 Top고金가�도|起 Top고金가�도\\n196_audio| 음.. 이상한 포인트에서 갑자기 의기양양해지네| 음.. 이상한 포인트에서 갑자기 의기양양해지네\\n197_audio| 여행자! 갑자기 왜 이러는 거야! 아카델미아 사람에게 잡히면 모든 것이 허사로 돌아가잖아!| 여행자! 갑자기 왜 이러는 거야! 아카델미아 사람에게 잡히면 모든 것이 허사로 돌아가잖아!\\n198_audio| 정말 쉽지 않았겠네| 정말 쉽지 않았겠네\\n199_audio| 흐흐 맞아 나도 이거였던 것 같아| 흐흐 맞아 나도 이거였던 것 같아\\n200_audio| 미코 빨리 어떡해 봐! 미코!| 미코 빨리 어떡해 봐! 미코!\\n201_audio| 저기 잠깐! 잠깐만!| 저기 잠깐! 잠깐만!\\n202_audio|的话 اس윤아...|的话 اس윤아...\\n203_audio| 에이, 오해 그레! 빨리 따라와!| 에이, 오해 그레! 빨리 따라와!\\n204_audio| 히히 안녕? 저기 혹시 모휘? 우린 무언가 길드의 의뢰를 받고 왔어!| 히히 안녕? 저기 혹시 모휘? 우린 무언가 길드의 의뢰를 받고 왔어!\\n205_audio| 말은 다 전했어! 문제 없을 거야!| 말은 다 전했어! 문제 없을 거야!\\n206_audio| 의문? 이해 안 되는 문제라도 있어?| 의문? 이해 안 되는 문제라도 있어?\\n207_audio| 300만이랑 299만은 별 차이 없잖아!| 300만이랑 299만은 별 차이 없잖아!\\n208_audio| 오문이 każhaus| 오문이 każhaus\\n209_audio| 힘들긴 했지만 대단한 일을 한 기분이 들어| 힘들긴 했지만 대단한 일을 한 기분이 들어\\n210_audio| 재미있었다면 다음에도 같이 놀자!| 재미있었다면 다음에도 같이 놀자!\\n211_audio| 이 공장에 있는 마신의 원한한테 분노는 최고의 식량이지| 이 공장에 있는 마신의 원한한테 분노는 최고의 식량이지\\n212_audio| 미코! 그걸 네가 먼저 말하면 어떡해!| 미코! 그걸 네가 먼저 말하면 어떡해!\\n213_audio| 그럼 이제 하려던 일을 하러 가볼까?| 그럼 이제 하려던 일을 하러 가볼까?\\n214_audio| 엄청 큰 구멍이네... 프레용은 이 안에서 살고 있는 걸까?| 엄청 큰 구멍이네... 프레용은 이 안에서 살고 있는 걸까?\\n215_audio| 아, 시내는 볼 수 현장을 직접 보게 될 줄이야! 그냥 보고 있을 순 없겠지?| 아, 시내는 볼 수 현장을 직접 보게 될 줄이야! 그냥 보고 있을 순 없겠지?\\n216_audio| 아! 이제 계속 앞으로 갈 수 있어!| 아! 이제 계속 앞으로 갈 수 있어!\\n217_audio| 근데 이거 어떻게 쓰는 거지? 조종하려면 엄청난 힘이 필요해 보여| 근데 이거 어떻게 쓰는 거지? 조종하려면 엄청난 힘이 필요해 보여\\n218_audio| 뭐? 그럼 실종자들이 이곳에 끌려왔다는 거야?| 뭐? 그럼 실종자들이 이곳에 끌려왔다는 거야?\\n219_audio| 응 응! 그럼 우리도 사이너한테 가본 다음 다른 사람들은 뭐라고 있는지 보러 가자!| 응 응! 그럼 우리도 사이너한테 가본 다음 다른 사람들은 뭐라고 있는지 보러 가자!\\n220_audio| 으아 다들 이렇게 열정적일 줄이야| 으아 다들 이렇게 열정적일 줄이야\\n221_audio| 에? 무슨 일인데?| 에? 무슨 일인데?\\n222_audio| 흑흑 조금만 참아| 흑흑 조금만 참아\\n223_audio| 비록 기사단을 싫어하지만 자신만의 방법으로 몬드를 지키고 있었구나.| 비록 기사단을 싫어하지만 자신만의 방법으로 몬드를 지키고 있었구나.\\n224_audio||\\n225_audio| 아니 아니지! 만약 선택할 수 있다면 넌 뭐랄 거야?| 아니 아니지! 만약 선택할 수 있다면 넌 뭐랄 거야?\\n226_audio| 무례신은 심판청에서 사형을 선고받았고, 현장에 있던 모든 사람이 놀랐지 설마, 무례신의 죄가 바로 폰타인의 원지인 걸까?| 무례신은 심판청에서 사형을 선고받았고, 현장에 있던 모든 사람이 놀랐지 설마, 무례신의 죄가 바로 폰타인의 원지인 걸까?\\n227_audio| 그러니까 조금만 손보면 된다는 거지!| 그러니까 조금만 손보면 된다는 거지!\\n228_audio| 우리 칭찬받았어!| 우리 칭찬받았어!\\n229_audio| 소가 마름대로 의식을 완료했어| 소가 마름대로 의식을 완료했어\\n230_audio| 그렇게 짧은 자기소개가 무슨 소용이야? 적어도 오해 아버지라고 부르는 지 정도는 알려줘야지!| 그렇게 짧은 자기소개가 무슨 소용이야? 적어도 오해 아버지라고 부르는 지 정도는 알려줘야지!\\n231_audio| 얼굴까지 울지 마 평화로운 지루함34 4 deals 버쉬로 소탕 부자 스카씌 조개 조개ря 로졌어| 얼굴까지 울지 마 평화로운 지루함34 4 deals 버쉬로 소탕 부자 스카씌 조개 조개ря 로졌어\\n232_audio| 그..후로는 어쩌지?| 그..후로는 어쩌지?\\n233_audio| 하지만 계속 웃고 있었잖아| 하지만 계속 웃고 있었잖아\\n234_audio| 하지만 저기 저 추추족들은 못 본 건가? 갑자기 공격할 수도 있는데| 하지만 저기 저 추추족들은 못 본 건가? 갑자기 공격할 수도 있는데\\n235_audio| 그런 만민탕의 음식은 태우세를 입맛에 안 맞겠어 다른 곳에 가보자| 그런 만민탕의 음식은 태우세를 입맛에 안 맞겠어 다른 곳에 가보자\\n236_audio| 흐흐, 말을 참 예쁘게 하네| 흐흐, 말을 참 예쁘게 하네\\n237_audio| 맞아 맞아! 베이몬도 세상에 그렇게 좋은 일이 있다는 건 못 믿겠어!| 맞아 맞아! 베이몬도 세상에 그렇게 좋은 일이 있다는 건 못 믿겠어!\\n238_audio| 대회가 점점 치열해지고 있어! 다른 참가자들은 뭐 하고 있는지 확인해보자!| 대회가 점점 치열해지고 있어! 다른 참가자들은 뭐 하고 있는지 확인해보자!\\n239_audio| 지금은 목숨도 보전하기 힘든 상황이야! 계획은 일단 보류하자!| 지금은 목숨도 보전하기 힘든 상황이야! 계획은 일단 보류하자!\\n240_audio| 주리야! 주리야! 우리가 완관을 대처져 왔어!| 주리야! 주리야! 우리가 완관을 대처져 왔어!\\n241_audio| 으휴 납득이 안돼! 우리가 여기까지 왔는데 결국 두뇌을 자드는...| 으휴 납득이 안돼! 우리가 여기까지 왔는데 결국 두뇌을 자드는...\\n242_audio| 아무튼 울트라캡션 짱짱 신검을 찾고 있어!| 아무튼 울트라캡션 짱짱 신검을 찾고 있어!\\n243_audio| 뭐? 메뉴를 뽑기로 뽑아?| 뭐? 메뉴를 뽑기로 뽑아?\\n244_audio| 에이 미안해 그냥 아카디아 유적이 어디 있는지 물어보려고 왔어| 에이 미안해 그냥 아카디아 유적이 어디 있는지 물어보려고 왔어\\n245_audio| 으으 나쁜 생각 안 했어! 빨리 주사장한테 돌려주자!| 으으 나쁜 생각 안 했어! 빨리 주사장한테 돌려주자!\\n246_audio| 팬말... 보물이 어째서 사라졌는지 알 것 같군| 팬말... 보물이 어째서 사라졌는지 알 것 같군\\n247_audio| 그랬구나 난 그냥 네 성격이 그래서 그런 줄 알았어| 그랬구나 난 그냥 네 성격이 그래서 그런 줄 알았어\\n248_audio| 으아! 으아!| 으아! 으아!\\n249_audio| 분명 좋아할 거야!| 분명 좋아할 거야!\\n250_audio| 아... 아! 조말 것 같아! 그러니까 무례신은 본타인에서 슈퍼스타 같은 존재라는 거지!| 아... 아! 조말 것 같아! 그러니까 무례신은 본타인에서 슈퍼스타 같은 존재라는 거지!\\n251_audio| 왜냐면 다른 사람이 아무리 믿음직스러워도 내겐 네가 최고니까! 히히! 응?| 왜냐면 다른 사람이 아무리 믿음직스러워도 내겐 네가 최고니까! 히히! 응?\\n252_audio| 그중에는 반드시 오빠의 소식 있을 거야| 그중에는 반드시 오빠의 소식 있을 거야\\n253_audio| 그게 누군데?| 그게 누군데?\\n254_audio| 하하! 해결했다!| 하하! 해결했다!\\n255_audio| 그럼 다행인데... 뭔가 고민이 있어 보여서...| 그럼 다행인데... 뭔가 고민이 있어 보여서...\\n256_audio| 어쩐지 재밌을 것 같은데? 나도 하고 싶어!| 어쩐지 재밌을 것 같은데? 나도 하고 싶어!\\n257_audio| 와! 뭔가 엄청난 게 나올 것 같아!| 와! 뭔가 엄청난 게 나올 것 같아!\\n258_audio| 그러고 보니 타이 나리에게 모든 계획을 털어놓지 않아도 괜찮겠어? 우리 믿지 못하지 않을까?| 그러고 보니 타이 나리에게 모든 계획을 털어놓지 않아도 괜찮겠어? 우리 믿지 못하지 않을까?\\n259_audio| 호픔하는 역시왔네| 호픔하는 역시왔네\\n260_audio| 아! 저기 봐! 저기 앉아있어! 설마 이곳에 사는 건 아니겠지?| 아! 저기 봐! 저기 앉아있어! 설마 이곳에 사는 건 아니겠지?\\n261_audio| 후, 사장님! 그 마음이 분명 아망제군에게 전해질 거야!| 후, 사장님! 그 마음이 분명 아망제군에게 전해질 거야!\\n262_audio| 결국은 치즈로가 하나를 낳고 있는 게 다잖아 그것도 애는 동자승한테 선물로 줘버렸지만| 결국은 치즈로가 하나를 낳고 있는 게 다잖아 그것도 애는 동자승한테 선물로 줘버렸지만\\n263_audio| 앗! club 해야ulptu!| 앗! club 해야ulptu!\\n264_audio| 하... 또 막다른 길이네... 기억 삭제 이론도 틀린 걸까?| 하... 또 막다른 길이네... 기억 삭제 이론도 틀린 걸까?\\n265_audio| 으아! 이 마물들은 어디서 뛰어나왔지? 빨리 해치워버리자!| 으아! 이 마물들은 어디서 뛰어나왔지? 빨리 해치워버리자!\\n266_audio| 정말 비관적인 예언이네. 오의 폰타인 사람이 죄를 가지고 태어난다는 거지? 정확히 무슨 뜻일까?| 정말 비관적인 예언이네. 오의 폰타인 사람이 죄를 가지고 태어난다는 거지? 정확히 무슨 뜻일까?\\n267_audio| 너 너 너 너는 아니 너희는 누구야?| 너 너 너 너는 아니 너희는 누구야?\\n268_audio| 프레미네! 갑자기 무슨 소리야! 방금 긍정적으로 생각하기로 주리아랑 약속했잖아!| 프레미네! 갑자기 무슨 소리야! 방금 긍정적으로 생각하기로 주리아랑 약속했잖아!\\n269_audio| 최근 한 기자가 메로피드 요새 잠이 파려다 실패하여 오라? 이 녀석 아직도 포기를 안 한 건가?| 최근 한 기자가 메로피드 요새 잠이 파려다 실패하여 오라? 이 녀석 아직도 포기를 안 한 건가?\\n270_audio| 그렇게 말해도...| 그렇게 말해도...\\n271_audio| 예쁘다! 게다가 힘이 넘치는 것 같아!| 예쁘다! 게다가 힘이 넘치는 것 같아!\\n272_audio| 복죽은 확보했고 히히! 이제 밤이 되길 기다리면 되겠어!| 복죽은 확보했고 히히! 이제 밤이 되길 기다리면 되겠어!\\n273_audio| 그래? 너한테도 그런 여유가 있구나| 그래? 너한테도 그런 여유가 있구나\\n274_audio| 후우 увид İstanbul| 후우 увид İstanbul\\n275_audio| 맞아! 설렘 왕생당이 볼 일이 있다고 해도 여기까지 오진 않았을 거야| 맞아! 설렘 왕생당이 볼 일이 있다고 해도 여기까지 오진 않았을 거야\\n276_audio| 어쩔 수 없지! 어딘지 알았으니 바로 쳐들어가면 되잖아!| 어쩔 수 없지! 어딘지 알았으니 바로 쳐들어가면 되잖아!\\n277_audio| 그러니까 최초의 현자는 처음부터 꿈속에 있었던 거네! 출발조차 안 했던 거구!| 그러니까 최초의 현자는 처음부터 꿈속에 있었던 거네! 출발조차 안 했던 거구!\\n278_audio| 응? 뭐가 끝장났다는 거야?| 응? 뭐가 끝장났다는 거야?\\n279_audio| 나도!| 나도!\\n280_audio| 어쩌지? 휴... 이번에도 타르탈리아의 도움을 받는 수밖에 없겠어| 어쩌지? 휴... 이번에도 타르탈리아의 도움을 받는 수밖에 없겠어\\n281_audio| 전선에 엄청 집착하는 것 같네| 전선에 엄청 집착하는 것 같네\\n282_audio| 하지만 그는 이곳에 없잖아!| 하지만 그는 이곳에 없잖아!\\n283_audio| 자비의 오랜만이야!| 자비의 오랜만이야!\\n284_audio| 그, 그런데! 내버려주면 또 다른 홀령소한 가이드가 나올지도 몰라!| 그, 그런데! 내버려주면 또 다른 홀령소한 가이드가 나올지도 몰라!\\n285_audio| 어쩌서 성은애 있는 거지?| 어쩌서 성은애 있는 거지?\\n286_audio| 저기 여행자 옆 사람한테 말을 거는 게 좋으려나? 아무도 없는데 옆에 앉으니까 엄청 어색해| 저기 여행자 옆 사람한테 말을 거는 게 좋으려나? 아무도 없는데 옆에 앉으니까 엄청 어색해\\n287_audio| 그건 좀 어렵네| 그건 좀 어렵네\\n288_audio| 에이 별거 아니야 너무 고마워도 사례같은건 할 필요 없어| 에이 별거 아니야 너무 고마워도 사례같은건 할 필요 없어\\n289_audio| 음 그렇구나... 근데 왜 여행자는 식물향을 맞고 괴로워했었던 거야?| 음 그렇구나... 근데 왜 여행자는 식물향을 맞고 괴로워했었던 거야?\\n290_audio| 알았어! 그럼 고맙게 받을게| 알았어! 그럼 고맙게 받을게\\n291_audio| 무슨 일이야! 상황이 급박하다고 우리가!| 무슨 일이야! 상황이 급박하다고 우리가!\\n292_audio| 맞아! 왜 말하다 많은 거야! 그리고는?| 맞아! 왜 말하다 많은 거야! 그리고는?\\n293_audio| 이 많은 상자는 너무 끔찍해!| 이 많은 상자는 너무 끔찍해!\\n294_audio| 으헤.. 제발 이루어져라..| 으헤.. 제발 이루어져라..\\n295_audio| 에이, 태도가 좀 수상한데?| 에이, 태도가 좀 수상한데?\\n296_audio| 응 응 선물 준비라면 우리가 도와줄 수 있어 음... 보수는? 희희 맛있는 거 사주면 돼| 응 응 선물 준비라면 우리가 도와줄 수 있어 음... 보수는? 희희 맛있는 거 사주면 돼\\n297_audio| 시부르지 너 정말 빠르다! 내가 나는 것보다 빠르겠는걸!| 시부르지 너 정말 빠르다! 내가 나는 것보다 빠르겠는걸!\\n298_audio| 하.. 정말 모르나봐| 하.. 정말 모르나봐\\n299_audio| 가자 가자! 안 물어보면 모르잖아| 가자 가자! 안 물어보면 모르잖아\\n300_audio| 그렇게나 많이?| 그렇게나 많이?\\n301_audio| 우리가 도울 일은 없어?| 우리가 도울 일은 없어?\\n302_audio| 두 번째 석판은 하늘에 셀렛티아가 떠있고 물의 신과 백성들이 고길 향에 무릎 꿇고 절하고 있어! 그런데도 셀렛티아는 벌을 내린 것 같네| 두 번째 석판은 하늘에 셀렛티아가 떠있고 물의 신과 백성들이 고길 향에 무릎 꿇고 절하고 있어! 그런데도 셀렛티아는 벌을 내린 것 같네\\n303_audio| 어디? 이건 지난번에 했던 독점 인터뷰네! 엄청 빨리 나왔다!| 어디? 이건 지난번에 했던 독점 인터뷰네! 엄청 빨리 나왔다!\\n304_audio| 알겠어! 그럼 여기서 얻을 수 있는 단서는 더 없겠네| 알겠어! 그럼 여기서 얻을 수 있는 단서는 더 없겠네\\n305_audio| 더 도와줄 일은 없어!| 더 도와줄 일은 없어!\\n306_audio| 하... 무슨 일 있나? 왜 성문 입구에 천원군이 몰려있지? 게다가 오임단까지...| 하... 무슨 일 있나? 왜 성문 입구에 천원군이 몰려있지? 게다가 오임단까지...\\n307_audio| 어?| 어?\\n308_audio| 이나주마의 배우들? 누군데? 우리도 아는 사람들이야?| 이나주마의 배우들? 누군데? 우리도 아는 사람들이야?\\n309_audio| 이 장치들을 파괴하고 추추족들의 고통을 끝내주자!| 이 장치들을 파괴하고 추추족들의 고통을 끝내주자!\\n310_audio| 사라졌어!| 사라졌어!\\n311_audio| 페이모는 별명 되게 잘 지어| 페이모는 별명 되게 잘 지어\\n312_audio| 늑대는 아주 신비로워 그렇게 자주 볼 수 있는 게 아니라고| 늑대는 아주 신비로워 그렇게 자주 볼 수 있는 게 아니라고\\n313_audio| 응? 뭐라고?| 응? 뭐라고?\\n314_audio| 그래! 이건 이미 꿈을 꾸다 정도로 끝나는 게 아니야!| 그래! 이건 이미 꿈을 꾸다 정도로 끝나는 게 아니야!\\n315_audio| 그 정도야?| 그 정도야?\\n316_audio| 어, 알았어! 알았다고! 그런 슬픔 표정 짖지 마! 꼭 네가 써야 하는 것처럼 말이야!| 어, 알았어! 알았다고! 그런 슬픔 표정 짖지 마! 꼭 네가 써야 하는 것처럼 말이야!\\n317_audio| 그런데 이 시간에 왜 혼자 멍하니 있는 거야?| 그런데 이 시간에 왜 혼자 멍하니 있는 거야?\\n318_audio| 진짜 내 타이 나리가 쓰러져 있어! 호소 도와주자!| 진짜 내 타이 나리가 쓰러져 있어! 호소 도와주자!\\n319_audio| 야 여행자! 너 또 나 놀린 거야?| 야 여행자! 너 또 나 놀린 거야?\\n320_audio| 히히, 둘이 사이가 참 좋구나!| 히히, 둘이 사이가 참 좋구나!\\n321_audio| 하... 그 여자의 완전히 사라졌어!| 하... 그 여자의 완전히 사라졌어!\\n322_audio| 아무튼 더는 유라가 다른 사람이랑 논쟁하지 못하게 해야 해| 아무튼 더는 유라가 다른 사람이랑 논쟁하지 못하게 해야 해\\n323_audio| 아 맞아! 아비디아 숲에 있을 때 현자가 그를 프로젝트에 초대하는 걸 봤었잖아! 아마 같은 일이겠지?| 아 맞아! 아비디아 숲에 있을 때 현자가 그를 프로젝트에 초대하는 걸 봤었잖아! 아마 같은 일이겠지?\\n324_audio| 하.. 우리가 도울 수 있는 건 정말 없는 것 같네.. 이제 뭐라면 될까?| 하.. 우리가 도울 수 있는 건 정말 없는 것 같네.. 이제 뭐라면 될까?\\n325_audio| 우린 못 봤는데?| 우린 못 봤는데?\\n326_audio| 내 특징을 다 뺏겨버리면 그 누구도 여행자 옆에 있는 나를 기억하지 못할 거야! 난 더 이상 유일무이한 존재가 아니게 된다고!| 내 특징을 다 뺏겨버리면 그 누구도 여행자 옆에 있는 나를 기억하지 못할 거야! 난 더 이상 유일무이한 존재가 아니게 된다고!\\n327_audio| 그건 내가 할 말이지! 나란 여행자는 여기서 일선을 돕고 있거든!| 그건 내가 할 말이지! 나란 여행자는 여기서 일선을 돕고 있거든!\\n328_audio| 어? 두지혜랑 얘기가 다 끝났나봐! 우리도 돌아가보자!| 어? 두지혜랑 얘기가 다 끝났나봐! 우리도 돌아가보자!\\n329_audio| 나 제대로 외운 거 맞지?| 나 제대로 외운 거 맞지?\\n330_audio| 우회하지 마! 그것 때문에 도운 건 아니니까! 네가 잃어버린 게 당근이나 양배추였어도 널 도왔을 거야!| 우회하지 마! 그것 때문에 도운 건 아니니까! 네가 잃어버린 게 당근이나 양배추였어도 널 도왔을 거야!\\n331_audio| 그건 딱 봐도 알 수 있는 거잖아| 그건 딱 봐도 알 수 있는 거잖아\\n332_audio| 하아... 아주 긴 여행을 한 것 같은 기분이야 힘들어 죽겠네| 하아... 아주 긴 여행을 한 것 같은 기분이야 힘들어 죽겠네\\n333_audio| 가에 대하라 가을몬| 가에 대하라 가을몬\\n334_audio| 어? 잠깐! 저 주각상... 아까도 이쪽을 보고 있었나?| 어? 잠깐! 저 주각상... 아까도 이쪽을 보고 있었나?\\n335_audio| 책의 내용은 마신전쟁 시대에 패배한 마신의 원형으로 전염병과 귀신, 괴물이 탄색했다는 거야!| 책의 내용은 마신전쟁 시대에 패배한 마신의 원형으로 전염병과 귀신, 괴물이 탄색했다는 거야!\\n336_audio| 그럼!| 그럼!\\n337_audio| 음... 페이모는 또 못 알아 듣겠는데| 음... 페이모는 또 못 알아 듣겠는데\\n338_audio| 여기서 기다릴래? 봄을 찾으면 돌려줄게| 여기서 기다릴래? 봄을 찾으면 돌려줄게\\n339_audio| 그래! 너도 힘들겠구나| 그래! 너도 힘들겠구나\\n340_audio| 내 생각엔 아주 못들어진 것 같은데| 내 생각엔 아주 못들어진 것 같은데\\n341_audio| 다이나리! 괜찮아!| 다이나리! 괜찮아!\\n342_audio| 세계수가 시들어서 숲속에는 죽음의 땅이 사막에는 모래 폭풍과 지진이 나타난 거라고 이해해도 되는 거지?| 세계수가 시들어서 숲속에는 죽음의 땅이 사막에는 모래 폭풍과 지진이 나타난 거라고 이해해도 되는 거지?\\n343_audio| 우와!ekt instit!| 우와!ekt instit!\\n344_audio| 으아차! 미안. 너무 놀라서 그만. 히이, 근데 여기 추리소설 진짜 재밌다!| 으아차! 미안. 너무 놀라서 그만. 히이, 근데 여기 추리소설 진짜 재밌다!\\n345_audio| 그러게 바람의 신의 선물이라며!| 그러게 바람의 신의 선물이라며!\\n346_audio| 게다가 녀석에게서 마술의 비밀에 발견할 기회일지도 몰라! 어때?| 게다가 녀석에게서 마술의 비밀에 발견할 기회일지도 몰라! 어때?\\n347_audio| 음 나쁘지 않은데 너도 먹어봐 우리 같이 먹자| 음 나쁘지 않은데 너도 먹어봐 우리 같이 먹자\\n348_audio| 우휴... 탱유봉행을 방해했으니 당연한 거잖아| 우휴... 탱유봉행을 방해했으니 당연한 거잖아\\n349_audio| 보물 사냥단 남쪽과 북쪽의 거물?| 보물 사냥단 남쪽과 북쪽의 거물?\\n350_audio| 네가 오자고 했으면서 왜 아무거나 좋다는 거야 그럼 엠바! 원하는 거 아무거나 말해봐!| 네가 오자고 했으면서 왜 아무거나 좋다는 거야 그럼 엠바! 원하는 거 아무거나 말해봐!\\n351_audio| 왜 정말? 왕랑이 한 말만 가지고?| 왜 정말? 왕랑이 한 말만 가지고?\\n352_audio| 두 사람들 정말 고마워!| 두 사람들 정말 고마워!\\n353_audio| 갈까? 제법뚜기 푼 일 갔던데| 갈까? 제법뚜기 푼 일 갔던데\\n354_audio| 하지만 윤홰를 끝내려면 주체가 자을식을 가지게 해야하잖아| 하지만 윤홰를 끝내려면 주체가 자을식을 가지게 해야하잖아\\n355_audio| 아, 그게 어떻게 된 거냐면...| 아, 그게 어떻게 된 거냐면...\\n356_audio| 금발에 특이한 옷차림을 한 낯선 사람? 전에도 한번 들어본 것 같은데?| 금발에 특이한 옷차림을 한 낯선 사람? 전에도 한번 들어본 것 같은데?\\n357_audio| 정말 의미란 곳이네 하지만 무서워할 거 없지 들어가 보자| 정말 의미란 곳이네 하지만 무서워할 거 없지 들어가 보자\\n358_audio| 으, 뒤에 무슨 말을 할지 너무 뻔해| 으, 뒤에 무슨 말을 할지 너무 뻔해\\n359_audio| 푸린아! 벌써 현장에 와 있었구나! 다른 사람들보다 훨씬 잊지 않네?| 푸린아! 벌써 현장에 와 있었구나! 다른 사람들보다 훨씬 잊지 않네?\\n360_audio| 아까부터 묻고 싶었던 건데 뭘 준비한다는 거야?| 아까부터 묻고 싶었던 건데 뭘 준비한다는 거야?\\n361_audio| 으휴 중요한 건 그게 아니잖아! 그런 상황이라면 분명 바로 체포될 거라고!| 으휴 중요한 건 그게 아니잖아! 그런 상황이라면 분명 바로 체포될 거라고!\\n362_audio| 흐허! 빨리 공격해! 슈퍼 펠몬 선풍을 써!| 흐허! 빨리 공격해! 슈퍼 펠몬 선풍을 써!\\n363_audio| 그러니까! 역시 난 눈치가 빨라!| 그러니까! 역시 난 눈치가 빨라!\\n364_audio| 으악!| 으악!\\n365_audio| 설마 크레이비가 거짓말을 한 걸까? 그건 아닌 것 같은데| 설마 크레이비가 거짓말을 한 걸까? 그건 아닌 것 같은데\\n366_audio| 설마 니가 불씨가 될 생각이야?| 설마 니가 불씨가 될 생각이야?\\n367_audio| 으아 깜짝이야! 이.. 이건 뭐지?| 으아 깜짝이야! 이.. 이건 뭐지?\\n368_audio| 하, 결국 너도 다크이오루가 누군지 모르는 거잖아| 하, 결국 너도 다크이오루가 누군지 모르는 거잖아\\n369_audio| 으악! 갑자기 뭐하는 거야! 오라! 보석 안에서 검은 게 흘러나오고 있네?| 으악! 갑자기 뭐하는 거야! 오라! 보석 안에서 검은 게 흘러나오고 있네?\\n370_audio| 어? 우리를 초대하는 거였어?| 어? 우리를 초대하는 거였어?\\n371_audio| 그나저나 두뇌를 자들을 보러 간 적 있어? 어떻게 지내고 있어? 호마야니 가문해서 외부인을 안들여보내 줘서 보러 갈 기회가 없었거든| 그나저나 두뇌를 자들을 보러 간 적 있어? 어떻게 지내고 있어? 호마야니 가문해서 외부인을 안들여보내 줘서 보러 갈 기회가 없었거든\\n372_audio| 맞아 맞아! 분위기가 장난 아니었다니까! 들어봐! 그게 말이지?| 맞아 맞아! 분위기가 장난 아니었다니까! 들어봐! 그게 말이지?\\n373_audio| 그래서 이 많은 실험을 한 거라니...| 그래서 이 많은 실험을 한 거라니...\\n374_audio| 저 잠깐! 마음의 준비가 필요해| 저 잠깐! 마음의 준비가 필요해\\n375_audio| 응 들으나 많아 돈 많은 분들이겠지| 응 들으나 많아 돈 많은 분들이겠지\\n376_audio| 뭐라고? 방금 무슨 맛이라고?| 뭐라고? 방금 무슨 맛이라고?\\n377_audio| 난 둥둥 모자와 팀워크가 더 잘 맞았으면 좋겠어 우리 눈빛만 보고도 바로 통화점 도로 말이야| 난 둥둥 모자와 팀워크가 더 잘 맞았으면 좋겠어 우리 눈빛만 보고도 바로 통화점 도로 말이야\\n378_audio| 그럼 콜라를 수습할 수 없을 지경이 되면 네가 직접 나서서 마지막으로 리워를 구해줄려 했다는 거야?| 그럼 콜라를 수습할 수 없을 지경이 되면 네가 직접 나서서 마지막으로 리워를 구해줄려 했다는 거야?\\n379_audio| 이빠, 왜 갑자기 험다 바는 거야?| 이빠, 왜 갑자기 험다 바는 거야?\\n380_audio| 넌 이런 기미를 어떻게 알고 있는 거야?| 넌 이런 기미를 어떻게 알고 있는 거야?\\n381_audio| 와하하하! 연날리기 대회의 1등은 나다! 이런 느낌으로?| 와하하하! 연날리기 대회의 1등은 나다! 이런 느낌으로?\\n382_audio| 그, 그건 맞지| 그, 그건 맞지\\n383_audio| 하.. 어떻게 해야 부자랑 친구할 수 있을까?| 하.. 어떻게 해야 부자랑 친구할 수 있을까?\\n384_audio| 그거 이제 와서 고민하는 거야?| 그거 이제 와서 고민하는 거야?\\n385_audio| 그럼 한 씨가 급하니 간다르바 성각으로 바로 출발하자!| 그럼 한 씨가 급하니 간다르바 성각으로 바로 출발하자!\\n386_audio| 뭐랄까? 최고 심판과는 좀 더 고급스러운 음료를 마실 줄 알았지| 뭐랄까? 최고 심판과는 좀 더 고급스러운 음료를 마실 줄 알았지\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_txt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fb01608-0477-48b6-b28b-d484bc835664",
   "metadata": {},
   "source": [
    "whisper have to install ffmpeg\n",
    "sudo apt update && sudo apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31eb2037-eed8-440b-abe1-4b9b11544d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"small\")\n",
    "\n",
    "i = 1\n",
    "\n",
    "result_txt = \"\"\n",
    "paimon_folder = 'datasets/wavs'\n",
    "\n",
    "while True:\n",
    "    tmp_txt = \"\"\n",
    "\n",
    "    audio_path = f'{i}_audio'  # 오디오 파일 저장 경로\n",
    "    transcription_path = os.path.join(paimon_folder, f'{i}_transcription.txt')  # 전사 파일 저장 경로\n",
    "    try:\n",
    "        with open(transcription_path, 'r') as transcription_file:\n",
    "            transcription = transcription_file.read()\n",
    "\n",
    "        tmp_txt = f\"{audio_path}|{transcription}|{transcription}\\n\"\n",
    "        result_txt += tmp_txt\n",
    "        i += 1\n",
    "    except:\n",
    "        print(\"done\")\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62538b8d-db50-4899-be65-7e2823e4afb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./datasets/metadata.txt\", 'w') as file:\n",
    "    file.write(result_txt)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1d21eb5-0c7a-4aa4-84b1-0c3418c94a53",
   "metadata": {},
   "source": [
    "여기서부터는 finetuning\n",
    "TTS finetuning\n",
    "https://docs.coqui.ai/en/latest/finetuning.html\n",
    "\n",
    "XTTS\n",
    "https://www.gpters.org/c/ai-developers/2c022a\n",
    "\n",
    "/home/pengejeen/paymon_v0.0.1/paimon_llama2-enhanced/tts_paimon/TTS/recipes/ljspeech/xtts_v2\n",
    "\n",
    "tokenizer.encode\n",
    "https://github.com/coqui-ai/TTS/issues/3356"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5865231b-b624-4ada-ad22-33aeaa8219be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> DVAE weights restored from: /home/pengejeen/paymon_v0.0.1/paimon_llama2-enhanced/tts_paimon/TTS/recipes/ljspeech/xtts_v2/run/training/XTTS_v2.0_original_model_files/dvae.pth\n",
      " | > Found 386 files in /home/pengejeen/paymon_v0.0.1/paimon_llama2-enhanced/tts_paimon/datasets\n",
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: False\n",
      " | > Precision: float32\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 1\n",
      " | > Num. of CPUs: 12\n",
      " | > Num. of Torch Threads: 1\n",
      " | > Torch seed: 1\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      " > Start Tensorboard: tensorboard --logdir=/home/pengejeen/paymon_v0.0.1/paimon_llama2-enhanced/tts_paimon/TTS/recipes/ljspeech/xtts_v2/run/training/paimon_ko-May-26-2024_11+23PM-58e6b6a\n",
      "\n",
      " > Model has 518442047 parameters\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/2\u001b[0m\n",
      " --> /home/pengejeen/paymon_v0.0.1/paimon_llama2-enhanced/tts_paimon/TTS/recipes/ljspeech/xtts_v2/run/training/paimon_ko-May-26-2024_11+23PM-58e6b6a\n",
      " > Filtering invalid eval samples!!\n",
      " > Total eval samples after filtering: 3\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 0.31461024284362793 \u001b[0m(+0)\n",
      "     | > avg_loss_text_ce: 0.03241344168782234 \u001b[0m(+0)\n",
      "     | > avg_loss_mel_ce: 3.4836602210998535 \u001b[0m(+0)\n",
      "     | > avg_loss: 3.516073703765869 \u001b[0m(+0)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 1/2\u001b[0m\n",
      " --> /home/pengejeen/paymon_v0.0.1/paimon_llama2-enhanced/tts_paimon/TTS/recipes/ljspeech/xtts_v2/run/training/paimon_ko-May-26-2024_11+23PM-58e6b6a\n",
      " > Sampling by language: dict_keys(['ko'])\n",
      "\n",
      "\u001b[1m > TRAINING (2024-05-26 23:23:13) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-05-26 23:23:14 -- STEP: 0/128 -- GLOBAL_STEP: 0\u001b[0m\n",
      "     | > loss_text_ce: 0.03278081491589546  (0.03278081491589546)\n",
      "     | > loss_mel_ce: 4.001546382904053  (4.001546382904053)\n",
      "     | > loss: 0.048027705401182175  (0.048027705401182175)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 0.6288  (0.6288208961486816)\n",
      "     | > loader_time: 0.4392  (0.43924784660339355)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-05-26 23:28:36 -- STEP: 50/128 -- GLOBAL_STEP: 50\u001b[0m\n",
      "     | > loss_text_ce: 0.04059693217277527  (0.03282948020845653)\n",
      "     | > loss_mel_ce: 3.8812294006347656  (3.5872834873199464)\n",
      "     | > loss: 0.04668841138482094  (0.04309658408164977)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 5.1857  (5.296987347602844)\n",
      "     | > loader_time: 0.0131  (0.011329407691955567)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2024-05-26 23:34:12 -- STEP: 100/128 -- GLOBAL_STEP: 100\u001b[0m\n",
      "     | > loss_text_ce: 0.028947018086910248  (0.033204166106879714)\n",
      "     | > loss_mel_ce: 3.6495046615600586  (3.5881004238128664)\n",
      "     | > loss: 0.043791092932224274  (0.043110769838094705)\n",
      "     | > current_lr: 5e-06 \n",
      "     | > step_time: 4.6467  (5.280790605545039)\n",
      "     | > loader_time: 0.0045  (0.011361868381500242)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      " | > Synthesizing test sentences.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.0610804557800293 \u001b[0m(-0.25352978706359863)\n",
      "     | > avg_loss_text_ce:\u001b[91m 0.03241471201181412 \u001b[0m(+1.2703239917755127e-06)\n",
      "     | > avg_loss_mel_ce:\u001b[92m 3.1961588859558105 \u001b[0m(-0.28750133514404297)\n",
      "     | > avg_loss:\u001b[92m 3.2285735607147217 \u001b[0m(-0.28750014305114746)\n",
      "\n",
      " > BEST MODEL : /home/pengejeen/paymon_v0.0.1/paimon_llama2-enhanced/tts_paimon/TTS/recipes/ljspeech/xtts_v2/run/training/paimon_ko-May-26-2024_11+23PM-58e6b6a/best_model_128.pth\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=\"0\" python3 /home/pengejeen/paymon_v0.0.1/paimon_llama2-enhanced/tts_paimon/TTS/recipes/ljspeech/xtts_v2/train_gpt_xtts.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ced41c0-b76f-4bec-b3e2-390cff78af97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Xtts(\n",
       "  (gpt): GPT(\n",
       "    (conditioning_encoder): ConditioningEncoder(\n",
       "      (init): Conv1d(80, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (attn): Sequential(\n",
       "        (0): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (1): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (2): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (3): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (4): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (5): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conditioning_dropout): Dropout1d(p=0.1, inplace=False)\n",
       "    (text_embedding): Embedding(6681, 1024)\n",
       "    (mel_embedding): Embedding(1026, 1024)\n",
       "    (gpt): GPT2Model(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-29): 30 x GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (wte): Embedding(1026, 1024)\n",
       "    )\n",
       "    (mel_pos_embedding): LearnedPositionEmbeddings(\n",
       "      (emb): Embedding(608, 1024)\n",
       "    )\n",
       "    (text_pos_embedding): LearnedPositionEmbeddings(\n",
       "      (emb): Embedding(404, 1024)\n",
       "    )\n",
       "    (final_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (text_head): Linear(in_features=1024, out_features=6681, bias=True)\n",
       "    (mel_head): Linear(in_features=1024, out_features=1026, bias=True)\n",
       "    (conditioning_perceiver): PerceiverResampler(\n",
       "      (proj_context): Identity()\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x ModuleList(\n",
       "          (0): Attention(\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=5460, bias=True)\n",
       "            (1): GEGLU()\n",
       "            (2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): RMSNorm()\n",
       "    )\n",
       "    (gpt_inference): GPT2InferenceModel(\n",
       "      (transformer): GPT2Model(\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-29): 30 x GPT2Block(\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (wte): Embedding(1026, 1024)\n",
       "      )\n",
       "      (pos_embedding): LearnedPositionEmbeddings(\n",
       "        (emb): Embedding(608, 1024)\n",
       "      )\n",
       "      (embeddings): Embedding(1026, 1024)\n",
       "      (final_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (lm_head): Sequential(\n",
       "        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=1024, out_features=1026, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (hifigan_decoder): HifiDecoder(\n",
       "    (waveform_decoder): HifiganGenerator(\n",
       "      (conv_pre): Conv1d(1024, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (ups): ModuleList(\n",
       "        (0): ParametrizedConvTranspose1d(\n",
       "          512, 256, kernel_size=(16,), stride=(8,), padding=(4,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ParametrizedConvTranspose1d(\n",
       "          256, 128, kernel_size=(16,), stride=(8,), padding=(4,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ParametrizedConvTranspose1d(\n",
       "          128, 64, kernel_size=(4,), stride=(2,), padding=(1,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ParametrizedConvTranspose1d(\n",
       "          64, 32, kernel_size=(4,), stride=(2,), padding=(1,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resblocks): ModuleList(\n",
       "        (0): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (conv_post): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "      (cond_layer): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conds): ModuleList(\n",
       "        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 64, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 32, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (speaker_encoder): ResNetSpeakerEncoder(\n",
       "      (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (layer1): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (instancenorm): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (torch_spec): Sequential(\n",
       "        (0): PreEmphasis()\n",
       "        (1): MelSpectrogram(\n",
       "          (spectrogram): Spectrogram()\n",
       "          (mel_scale): MelScale()\n",
       "        )\n",
       "      )\n",
       "      (attention): Sequential(\n",
       "        (0): Conv1d(2048, 128, kernel_size=(1,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Conv1d(128, 2048, kernel_size=(1,), stride=(1,))\n",
       "        (4): Softmax(dim=2)\n",
       "      )\n",
       "      (fc): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from TTS.tts.configs.xtts_config import XttsConfig\n",
    "from TTS.tts.models.xtts import Xtts\n",
    "\n",
    "#if you learning new model, please update PATH\n",
    "PATH = \"/home/pengejeen/paymon_v0.0.1/paimon_llama2-enhanced/tts_paimon/TTS/recipes/ljspeech/xtts_v2/run/training/paimon_ko-May-26-2024_11+23PM-58e6b6a\"\n",
    "\n",
    "TOKENIZER_PATH = \"/home/pengejeen/paymon_v0.0.1/paimon_llama2-enhanced/tts_paimon/TTS/recipes/ljspeech/xtts_v2/run/training/XTTS_v2.0_original_model_files/vocab.json\"\n",
    "\n",
    "print(\"Loading model...\")\n",
    "config = XttsConfig()\n",
    "config.load_json(f\"{PATH}/config.json\")\n",
    "\n",
    "model = Xtts.init_from_config(config)\n",
    "model.load_checkpoint(\n",
    "    config,\n",
    "    checkpoint_dir = f\"{PATH}\",\n",
    "    vocab_path = TOKENIZER_PATH,\n",
    "    use_deepspeed=False  \n",
    ")\n",
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cee213d4-4b3c-43ad-8ea8-401fdff00cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing speaker latents...\n",
      "Inference...\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing speaker latents...\")\n",
    "gpt_cond_latent, speaker_embedding = model.get_conditioning_latents(\n",
    "    audio_path=[\"./datasets/wavs/2_audio.wav\"]\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Inference...\")\n",
    "out = model.inference(\n",
    "    \"아니 이게 정말 맞는거야?\",\n",
    "    \"ko\",\n",
    "    gpt_cond_latent,\n",
    "    speaker_embedding,\n",
    "    temperature=0.7\n",
    ")\n",
    "torchaudio.save(\"./output.wav\", torch.tensor(out[\"wav\"]).unsqueeze(0), 24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29723cfe-4dfb-464f-ac87-d3b8fad15ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.16.2 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=/home/pengejeen/paymon_v0.0.1/paimon_llama2-enhanced/tts_paimon/TTS/recipes/ljspeech/xtts_v2/run/training/paimon_ko-May-26-2024_11+23PM-58e6b6a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dc18ba65-d543-46e7-8d62-95e7439087ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n",
      " > Text: 시발\n",
      " > Text splitted to sentences.\n",
      "['시발']\n",
      " > Processing time: 0.9812474250793457\n",
      " > Real-time factor: 0.5280287417756632\n",
      " > Saving output to tts_output.wav\n"
     ]
    }
   ],
   "source": [
    " !tts --model_name tts_models/multilingual/multi-dataset/xtts_v2 \\\n",
    "     --text \"시발\" \\\n",
    "     --speaker_idx \"Ana Florence\" \\\n",
    "     --language_idx ko \\\n",
    "     --use_cuda true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
